import zmq
from multiprocessing import Process
import zmq
import multiprocessing
from traceback import TracebackType
import socket
import uuid
from typing import Any, Sequence


# zmq stream connector --
# self.index to keep an element each time
# if there are no element left in the stream, keep returning other wise
# identifier for the stream itself
# put --> add elements to the steam --> its local
# get --> next elements to the stream --> distubuted  (this is dictionary and not file based)
# goal: avoid doing this for every connector

# end goal: put and get functions with zmq
# add it to margo
# benchmarks

# copy zmq and add zmq connectors
# no while loops
# use self index
# modify zmq stream server and add implemantion to it
# run it to see if it works


class ZeroMQConnector:
    """ZeroMQ-based distributed in-memory connector.

    Note:
        The first instance of this connector created on a process will
        spawn a [`ZeroMQServer`][proxystore.connectors.dim.zmq.ZeroMQServer]
        that will store data. Hence, this connector just acts as an interface
        to that server.

    Args:
        address: The network IP address to use. Takes precedence over
            `interface` if both are provided.
        interface: The network interface to use. `address` arg takes precedence
            if both are provided.
        port: The desired port for the spawned server.
        chunk_length: Message chunk size in bytes. Defaults to
            `MAX_CHUNK_LENGTH_DEFAULT`.
        timeout: Timeout in seconds to try connecting to local server before
            spawning one.

    Raises:
        ServerTimeoutError: If a local server cannot be connected to within
            `timeout` seconds, and a new local server does not response within
            `timeout` seconds after being started.
    """

    def __init__(
        self,
        port: int,
        address: str | None = None,
        interface: str | None = None,
        chunk_length: int | None = None,
        timeout: float = 1,
    ) -> None:
        # ZMQ is not a default dependency so we don't want to raise
        # an error unless the user actually tries to use this code
        if zmq_import_error is not None:  # pragma: no cover
            raise zmq_import_error

        self._address = address
        self._interface = interface
        self.port = port
        self.chunk_length = (
            MAX_CHUNK_LENGTH_DEFAULT if chunk_length is None else chunk_length
        )
        self.timeout = timeout

        if self._address is not None:
            self.address = self._address
        elif self._interface is not None:  # pragma: darwin no cover
            self.address = get_ip_address(self._interface)
        else:
            host = socket.gethostname()
            self.address = socket.gethostbyname(host)

        self.url = f"tcp://{self.address}:{self.port}"

        self.server: multiprocessing.Process | None
        try:
            logger.info(
                f"Connecting to local server (url={self.url})...",
            )
            wait_for_server(self.address, self.port, self.timeout)
            logger.info(
                f"Connected to local server (url={self.url})",
            )
        except ServerTimeoutError:
            logger.info(
                "Failed to connect to local server "
                f"(address={self.url}, timeout={self.timeout})",
            )
            self.server = spawn_server(
                self.address,
                self.port,
                chunk_length=self.chunk_length,
                spawn_timeout=self.timeout,
            )
            logger.info(f"Spawned local server (url={self.url})")
        else:
            self.server = None

        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.REQ)

    def __enter__(self) -> Self:
        return self

    def __exit__(
        self,
        exc_type: type[BaseException] | None,
        exc_value: BaseException | None,
        exc_traceback: TracebackType | None,
    ) -> None:
        self.close()

    def _send_rpcs(self, rpcs: Sequence[RPC]) -> list[RPCResponse]:
        """Send an RPC request to the server.

        Args:
            rpcs: List of RPCs to invoke on local server.

        Returns:
            List of RPC responses.

        Raises:
            Exception: Any exception returned by the local server.
        """
        responses = []

        for rpc in rpcs:
            message = serialize(rpc)
            url = f"tcp://{rpc.key.peer_host}:{rpc.key.peer_port}"
            with self.socket.connect(url):
                self.socket.send_multipart(
                    list(utils.chunk_bytes(message, self.chunk_length)),
                )
                logger.debug(
                    f"Sent {rpc.operation.upper()} RPC (key={rpc.key})",
                )
                result = b"".join(self.socket.recv_multipart())

            response = deserialize(result)
            logger.debug(
                f"Received {rpc.operation.upper()} RPC response "
                f"(key={response.key}, "
                f"exception={response.exception is not None})",
            )

            if response.exception is not None:
                raise response.exception

            assert rpc.operation == response.operation
            assert rpc.key == response.key

            responses.append(response)

        return responses

    def close(self, kill_server: bool = True) -> None:
        """Close the connector.

        Args:
            kill_server: Whether to kill the server process. If this instance
                did not spawn the local node's server process, this is a
                no-op.
        """
        if kill_server and self.server is not None:
            self.server.terminate()
            self.server.join()
            logger.info(
                "Terminated local server on connector close "
                f"(pid={self.server.pid})",
            )

        self.socket.close()
        self.context.term()
        logger.info("Closed ZMQ connector")

    def config(self) -> dict[str, Any]:
        """Get the connector configuration.

        The configuration contains all the information needed to reconstruct
        the connector object.
        """
        return {
            "address": self._address,
            "interface": self._interface,
            "port": self.port,
            "chunk_length": self.chunk_length,
            "timeout": self.timeout,
        }

    @classmethod
    def from_config(cls, config: dict[str, Any]) -> ZeroMQConnector:
        """Create a new connector instance from a configuration.

        Args:
            config: Configuration returned by `#!python .config()`.
        """
        return cls(**config)

    def evict(self, key: DIMKey) -> None:
        """Evict the object associated with the key.

        Args:
            key: Key associated with object to evict.
        """
        rpc = RPC(operation="evict", key=key)
        self._send_rpcs([rpc])

    def exists(self, key: DIMKey) -> bool:
        """Check if an object associated with the key exists.

        Args:
            key: Key potentially associated with stored object.

        Returns:
            If an object associated with the key exists.
        """
        rpc = RPC(operation="exists", key=key)
        (response,) = self._send_rpcs([rpc])
        assert response.exists is not None
        return response.exists

    def get(self, key: DIMKey) -> bytes | None:
        """Get the serialized object associated with the key.

        Args:
            key: Key associated with the object to retrieve.

        Returns:
            Serialized object or `None` if the object does not exist.
        """
        rpc = RPC(operation="get", key=key)
        (result,) = self._send_rpcs([rpc])
        return result.data

    def get_batch(self, keys: Sequence[DIMKey]) -> list[bytes | None]:
        """Get a batch of serialized objects associated with the keys.

        Args:
            keys: Sequence of keys associated with objects to retrieve.

        Returns:
            List with same order as `keys` with the serialized objects or \
            `None` if the corresponding key does not have an associated object.
        """
        rpcs = [RPC(operation="get", key=key) for key in keys]
        responses = self._send_rpcs(rpcs)
        return [r.data for r in responses]

    def put(self, obj: bytes) -> DIMKey:
        """Put a serialized object in the store.

        Args:
            obj: Serialized object to put in the store.

        Returns:
            Key which can be used to retrieve the object.
        """
        key = DIMKey(
            dim_type="zmq",
            obj_id=str(uuid.uuid4()),
            size=len(obj),
            peer_host=self.address,
            peer_port=self.port,
        )
        rpc = RPC(operation="put", key=key, data=obj)
        self._send_rpcs([rpc])
        return key

    def put_batch(self, objs: Sequence[bytes]) -> list[DIMKey]:
        """Put a batch of serialized objects in the store.

        Args:
            objs: Sequence of serialized objects to put in the store.

        Returns:
            List of keys with the same order as `objs` which can be used to \
            retrieve the objects.
        """
        keys = [
            DIMKey(
                dim_type="zmq",
                obj_id=str(uuid.uuid4()),
                size=len(obj),
                peer_host=self.address,
                peer_port=self.port,
            )
            for obj in objs
        ]
        rpcs = [RPC(operation="put", key=key, data=obj) for key, obj in zip(keys, objs)]
        self._send_rpcs(rpcs)
        return keys

    class ProxyStream:
        def __init__(self):
            self.data_packets = []
            self.is_end = False

        def append(self, data):
            self.data_packets.append(data)

        def next_data(self):
            if self.data_packets:
                return self.data_packets.pop(0)
            else:
                return None  # Return None when no more data available

        def is_end_of_stream(self):
            return self.is_end

        def end_stream(self):
            self.is_end = True

        def put(self, obj: bytes) -> DIMKey:
            key = self.connector.put(obj)
            return key

        def get(self, key: DIMKey) -> bytes | None:
            return self.connector.get(key)

        """def producer(stream):
                i = 0
                while i < 1000:
                data = generate_data()
                stream.append(data)
                i+= 1

                stream.end_stream()
                print('Stream complete')
                return stream
        """

    ####replacing the while loop####

    def producer(connector: ZeroMQConnector):
        self.index = 0

    def produce_data():
        if self.index < 1000:
            data = generate_data()
            key = connector.put(data)
            self.index += 1
            produce_data()
        else:
            connector.end_stream()
            print("Stream complete")

    produce_data()

    def generate_data():
        return "Data"

    def end_of_stream_condition(i):
        return i > 100


def server():
    context = zmq.Context()
    socket = context.socket(zmq.REP)
    socket.bind("tcp://*:5555")

    stream = ProxyStream()
    print(stream.is_end_of_stream())
    socket.recv()

    if self.index < 1000:
            data = generate_data()
            key = connector.put(data)
            self.index += 1
            produce_data()
    else:
            connector.end_stream()
            print("Stream complete")

    '''while not stream.is_end_of_stream():
        data = stream.next_data()
        print(data)
        socket.send_string(data)
        socket.recv()
    '''
    socket.send_string("END")

    socket.close()
    context.term()


def client():
    context = zmq.Context()
    socket = context.socket(zmq.REQ)
    socket.connect("tcp://localhost:5555")

    socket.send_string("send now")

    """while True:
        data = socket.recv_string()

        if data == "END":
            break

        process_data(data)

        socket.send_string("ACK")
    """
    socket.close()
    context.term()


def consumer(stream):
    data_iterator = iter(stream)
    
    for data in data_iterator:
        if data is None:
            break
        process_data(data)

def process_data(data):
    print("Processing data:", data)

if __name__ == "__main__":
    server_connector = ZeroMQConnector(port=5555)
    Process(target=server, args=(server_connector,)).start()

    client()

    server_connector.close()
